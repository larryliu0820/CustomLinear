{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.cpp_extension\n",
    "\n",
    "compiled_lib = torch.utils.cpp_extension.load(\n",
    "    name='Int8PackedLinear',\n",
    "    sources=['LlamaCppInt8Linear.mm'],\n",
    "    extra_cflags=['-std=c++17'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "\n",
    "assert torch.backends.mps.is_available()\n",
    "\n",
    "def test_speedup():\n",
    "    mps_device = torch.device(\"mps\")  # Device object representing GPU.\n",
    "    custom_mps_linear = 0\n",
    "    default_linear = 0\n",
    "    weight = torch.randn(2048, 768, device=mps_device, dtype=torch.int8)\n",
    "    input = torch.randn(128, 768, device=mps_device, dtype=torch.float32) # M = 128, N = 2048, K = 768\n",
    "    scale = torch.randn(2048, device=mps_device, dtype=torch.float32)\n",
    "    # Quantized linear: Linear(in_features=768, out_features=2048) * scale\n",
    "\n",
    "    # Measures time.\n",
    "    for _ in range(100):\n",
    "        start = time.time()\n",
    "        torch.ops.aten._weight_int8pack_mm(input, weight, scale)\n",
    "        torch.mps.synchronize()\n",
    "        default_linear += time.time() - start\n",
    "\n",
    "        start = time.time()\n",
    "        compiled_lib.llama_cpp_mps_int8_linear(input, weight, scale)\n",
    "        torch.mps.synchronize()\n",
    "        custom_mps_linear += time.time() - start\n",
    "\n",
    "    speedup = default_linear / custom_mps_linear\n",
    "    print('Default int8 QLinear: {:.3f} us | Custom int8 QLinear {:.3f} us. ({:.3f} times faster)'.format(\n",
    "        default_linear * 1e6/1e5, custom_mps_linear * 1e6/1e5, speedup))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default int8 QLinear: 0.849 us | Custom int8 QLinear 0.661 us. (1.284 times faster)\n"
     ]
    }
   ],
   "source": [
    "test_speedup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 2048])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "m = torch.nn.Linear(768, 2048)\n",
    "weight = torch.randn(2048, 768)\n",
    "m.weight = torch.nn.Parameter(weight)\n",
    "input = torch.randn(128, 768)\n",
    "output = m(input)\n",
    "print(output.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 2048])\n"
     ]
    }
   ],
   "source": [
    "mps_device = torch.device(\"mps\")  # Device object representing GPU.\n",
    "weight = torch.randn(2048, 768, device=mps_device, dtype=torch.int8)\n",
    "input = torch.randn(128, 768, device=mps_device, dtype=torch.float32) # M = 128, N = 2048, K = 768\n",
    "scale = torch.randn(2048, device=mps_device, dtype=torch.float32)\n",
    "res1 = torch.ops.aten._weight_int8pack_mm(input, weight, scale)\n",
    "print(res1.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "res2 = compiled_lib.llama_cpp_mps_int8_linear(input, weight, scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 2048])\n"
     ]
    }
   ],
   "source": [
    "print(res2.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ -7.2068, -13.4481, -18.3802,  ...,  10.1890,  -2.2464,   1.5332],\n",
      "        [ -3.5948,   8.0580,  13.1837,  ..., -14.9112,  -9.6422,  -0.7589],\n",
      "        [  8.6552,  26.3780,  -3.4192,  ..., -36.6986, -10.1032,  14.1250],\n",
      "        ...,\n",
      "        [  4.3094, -31.0385,   3.6036,  ...,  -1.5528, -36.5997,  -2.1174],\n",
      "        [  5.9805,   7.4148, -27.7217,  ..., -18.8047,  -4.7120,   8.9746],\n",
      "        [ -2.2707, -12.3608,  14.5149,  ...,  24.0632,  25.4688,  -6.0178]],\n",
      "       device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "print(res1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 14.5421,  10.2357,  40.4167,  ..., -21.8944,  60.1607,  16.0577],\n",
      "        [  8.4213,   5.3934,  91.2100,  ...,  28.1776, -24.6787,  -7.3789],\n",
      "        [-14.5463,  -1.6143,  10.3095,  ...,  -3.4682, -63.5541, -27.2303],\n",
      "        ...,\n",
      "        [ 11.3661, -27.6764,  14.9066,  ...,  -6.6825,  -2.6358,   5.4985],\n",
      "        [ 32.8333,  31.9119, -30.6715,  ..., -13.7488, -39.2429, -15.3178],\n",
      "        [  7.5256,  25.4646,   3.0442,  ...,  -8.3438,  21.2945,  30.2778]],\n",
      "       device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "print(res2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(res1, res2, atol=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 64])\n"
     ]
    }
   ],
   "source": [
    "mps_device = torch.device(\"mps\")  # Device object representing GPU.\n",
    "# Create a tensor with values from 0 to 127\n",
    "row = torch.arange(32, device=mps_device, dtype=torch.int8)\n",
    "# Repeat the row 64 times to create a 64x128 tensor\n",
    "weight = row.repeat(64, 1)\n",
    "input = torch.ones(32, 32, device=mps_device, dtype=torch.float32) # M = 128, N = 2048, K = 768\n",
    "scale = torch.ones(64, device=mps_device, dtype=torch.float32)\n",
    "res1 = torch.ops.aten._weight_int8pack_mm(input, weight, scale)\n",
    "print(res1.size())\n",
    "res2 = compiled_lib.llama_cpp_mps_int8_linear(input, weight, scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[496., 496., 496.,  ..., 496., 496., 496.],\n",
      "        [496., 496., 496.,  ..., 496., 496., 496.],\n",
      "        [496., 496., 496.,  ..., 496., 496., 496.],\n",
      "        ...,\n",
      "        [496., 496., 496.,  ..., 496., 496., 496.],\n",
      "        [496., 496., 496.,  ..., 496., 496., 496.],\n",
      "        [496., 496., 496.,  ..., 496., 496., 496.]], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "print(res1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[496., 496., 496.,  ..., 496., 496., 496.],\n",
      "        [496., 496., 496.,  ..., 496., 496., 496.],\n",
      "        [496., 496., 496.,  ..., 496., 496., 496.],\n",
      "        ...,\n",
      "        [496., 496., 496.,  ..., 496., 496., 496.],\n",
      "        [496., 496., 496.,  ..., 496., 496., 496.],\n",
      "        [496., 496., 496.,  ..., 496., 496., 496.]], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "print(res2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tensor with values from 0 to 127\n",
    "row = torch.arange(128)\n",
    "# Repeat the row 64 times to create a 64x128 tensor\n",
    "tensor = row.repeat(64, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  0,   1,   2,  ..., 125, 126, 127],\n",
      "        [  0,   1,   2,  ..., 125, 126, 127],\n",
      "        [  0,   1,   2,  ..., 125, 126, 127],\n",
      "        ...,\n",
      "        [  0,   1,   2,  ..., 125, 126, 127],\n",
      "        [  0,   1,   2,  ..., 125, 126, 127],\n",
      "        [  0,   1,   2,  ..., 125, 126, 127]])\n"
     ]
    }
   ],
   "source": [
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 64])\n"
     ]
    }
   ],
   "source": [
    "mps_device = torch.device(\"mps\")  # Device object representing GPU.\n",
    "# Create a tensor with values from 0 to 127\n",
    "row = torch.arange(32, device=mps_device, dtype=torch.int8)\n",
    "# Repeat the row 64 times to create a 64x128 tensor\n",
    "weight = torch.ones(64, 32, device=mps_device, dtype=torch.int8)\n",
    "input = torch.ones(32, 32, device=mps_device, dtype=torch.float32) # M = 128, N = 2048, K = 768\n",
    "scale = torch.ones(64, device=mps_device, dtype=torch.float32)\n",
    "res1 = torch.ops.aten._weight_int8pack_mm(input, weight, scale)\n",
    "print(res1.size())\n",
    "res2 = compiled_lib.llama_cpp_mps_int8_linear(input, weight, scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[32., 32., 32.,  ..., 32., 32., 32.],\n",
      "        [32., 32., 32.,  ..., 32., 32., 32.],\n",
      "        [32., 32., 32.,  ..., 32., 32., 32.],\n",
      "        ...,\n",
      "        [32., 32., 32.,  ..., 32., 32., 32.],\n",
      "        [32., 32., 32.,  ..., 32., 32., 32.],\n",
      "        [32., 32., 32.,  ..., 32., 32., 32.]], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "print(res1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[32., 32., 32.,  ..., 32., 32., 32.],\n",
      "        [32., 32., 32.,  ..., 32., 32., 32.],\n",
      "        [32., 32., 32.,  ..., 32., 32., 32.],\n",
      "        ...,\n",
      "        [32., 32., 32.,  ..., 32., 32., 32.],\n",
      "        [32., 32., 32.,  ..., 32., 32., 32.],\n",
      "        [32., 32., 32.,  ..., 32., 32., 32.]], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "print(res2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mps_device = torch.device(\"mps\")  # Device object representing GPU.\n",
    "# Create a tensor with values from 0 to 127\n",
    "row = torch.arange(32, device=mps_device, dtype=torch.int8)\n",
    "# Repeat the row 64 times to create a 64x128 tensor\n",
    "weight = torch.ones(64, 32, device=mps_device, dtype=torch.float32)\n",
    "input = torch.ones(32, 32, device=mps_device, dtype=torch.float32) # M = 128, N = 2048, K = 768\n",
    "\n",
    "res2 = compiled_lib.llama_cpp_mm(input, weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[32., 32., 32.,  ..., 32., 32., 32.],\n",
      "        [32., 32., 32.,  ..., 32., 32., 32.],\n",
      "        [32., 32., 32.,  ..., 32., 32., 32.],\n",
      "        ...,\n",
      "        [ 1.,  1.,  1.,  ...,  1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.,  ...,  1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.,  ...,  1.,  1.,  1.]], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "print(res2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[32., 32., 32.,  ..., 32., 32., 32.],\n",
       "        [32., 32., 32.,  ..., 32., 32., 32.],\n",
       "        [32., 32., 32.,  ..., 32., 32., 32.],\n",
       "        ...,\n",
       "        [32., 32., 32.,  ..., 32., 32., 32.],\n",
       "        [32., 32., 32.,  ..., 32., 32., 32.],\n",
       "        [32., 32., 32.,  ..., 32., 32., 32.]], device='mps:0')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ops.aten.mm(input, weight.transpose(1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-6.6626,  5.1726],\n",
      "        [ 9.0734,  2.4952]], device='mps:0')\n",
      "tensor([[-6.6632,  5.1737],\n",
      "        [ 9.0718,  2.4982]], device='mps:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight = torch.randn(2, 32, device=mps_device, dtype=torch.float32)\n",
    "input = torch.randn(2, 32, device=mps_device, dtype=torch.float32)\n",
    "\n",
    "res1 = torch.ops.aten.mm(input, weight.transpose(1, 0))\n",
    "res2 = compiled_lib.llama_cpp_mm(input, weight)\n",
    "print(res1)\n",
    "print(res2)\n",
    "torch.allclose(res1, res2, atol=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "executorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
